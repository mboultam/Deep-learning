{"cells":[{"cell_type":"markdown","metadata":{"id":"MSgiKnAs1BbN"},"source":["**TP n°5** : Learning to Rank et Ré-identification"]},{"cell_type":"markdown","metadata":{"id":"AvaKH1dZvg2B"},"source":["#Plan\n","\n","## Partie I: un problème de learning-to-rank\n","\n","- Learning to order things \n","- RankNet loss\n","- Listwise Loss\n","\n","## Partie II: un problème de ré-identification\n","\n","- triplet loss avec MNIST + triplet loss\n","- plus dur avec données webcam\n","\n","Durée : 4 h"]},{"cell_type":"markdown","metadata":{"id":"P1waEt7NJgSx"},"source":["**Partie I** :\n","\n","On distingue plusieurs problème sous l'étiquette \"[learning-to-rank](https://link.springer.com/content/pdf/10.1007/978-3-642-15880-3_20.pdf)\".\\\n","Il peut s'agir, par exemple de ranger une liste de contenus par pertinence en fonction d'une requête. Ici, le tri s'effectue sur les possibles sorties du modèle : on parle de *label ranking*.\\\n","Il peut aussi s'agir de trier des images dans un ensemble en fonction d'un critère particulier.\n","Là, le tri s'effectue sur les entrées du modèle; pour décrire cette situation, les termes suivants sont souvent utilisés: *object ranking*, *learning to order things*. \\\n","Mais dans les deux cas, on ne dispose pour apprendre que d'arrangements. Par exemple des paires d'images ordonnées. \n","\n","Dans ce TP, nous illustrons la deuxième situation, à partir d'images de synthèse très simples. Toutes les images contiennent en mélange un disque et un nombre variable de rectangles de formes différentes. Le but est de trier les images en fonction de l'intensité des pixels sur le disque.\\\n","Pour le faire, nous nous plaçons dans un contexte standard où on dispose de paires d'images ordonnées. Sur ces paires, nous entraînerons un réseau de neurones pour construire une \"fonction de rang\" (*ranker*) à valeurs réelles dont les sorties permettent de trier les images.\n"]},{"cell_type":"markdown","metadata":{"id":"Qtq1hUDdoSDC"},"source":["**Exercice n°1** : construction du problème\n","\n","Les cellules suivantes permettent de:\n","- générer un jeu de données sur votre drive (train+val et test)\n","- définir un Dataset qui met à disposition des paires d'images et une comparaison sur le critère de l'intensité du disque (\"0\" si le disque est plus intense sur la première image, \"1\" sinon).\n","- visualiser un premier batch"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":96080,"status":"error","timestamp":1670592196471,"user":{"displayName":"pierre lepetit","userId":"00153244657746066434"},"user_tz":-60},"id":"WNcrOkxx5l7G","outputId":"50e73be5-af8c-41a3-d47f-347d669fa8f6"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-6921a7270192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('drive/MyDrive/...')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5yBBrlb5gia"},"outputs":[],"source":["import os\n","from os.path import join\n","ls = lambda rep: sorted(os.listdir(rep))\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader, sampler\n","\n","import matplotlib.pyplot as plt\n","import copy\n","from random import randint, choice\n","\n","#other\n","#from datasets import *\n","from archis import *\n","from utile_tp5I import *\n","#from train_and_test import *\n"," \n","root = r\".\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DM4QiDC95gak"},"outputs":[],"source":["dir_trainval = join(root, r\"train\")\n","generate_dataset(dir_trainval, size_dataset=10000)\n","\n","dir_test = join(root, r\"test\")\n","generate_dataset(dir_test, size_dataset=2000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KfbAe6ca5f3V"},"outputs":[],"source":["# Récupérations des valeurs cibles (normalement inaccessibles)\n","\n","# path des images:\n","dir_images_trainval = os.path.join(dir_trainval, 'images')\n","dir_images_test = os.path.join(dir_test, 'images')\n","\n","# valeurs cibles train+val\n","name_dic = os.path.join(dir_trainval, 'labels_synthese.pickle')\n","with open(name_dic, 'rb') as handle:\n","    dic = pickle.load( handle)\n","\n","\n","# valeurs cibles test\n","name_dic_test = os.path.join(dir_test, 'labels_synthese.pickle')\n","with open(name_dic_test, 'rb') as handle:\n","    dic_test = pickle.load( handle)\n","    \n","# split train / val (8000/2000)\n","names = np.array(ls(dir_images_trainval))\n","\n","train_indices = list(range(0,8000))\n","names_train = names[train_indices]\n","val_indices = list(range(8000,10000))\n","names_val = names[val_indices]\n","names_test = ls(dir_images_test)\n","\n","# nb: pour sep. aléatoire : utiliser sklearn.model_selection.train_test_split as tts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pC2CQnsDREe"},"outputs":[],"source":["# si erreur :\n","# from shutil import rmtree\n","# rmtree(dir_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fv4HHS6Y67lE"},"outputs":[],"source":["#%% Augmentation de données\n","class super_flip(object):\n","    \"\"\"\n","    Les 8 transformations\n","    générées par R(Pi/2) et sym/axe vertical\n","    \"\"\"\n","    def __init__(self,nb):\n","        self.nb=nb\n","    def __call__(self, image):\n","        # hérésie : normalement, torch.randint...\n","        n = randint(0, self.nb)\n","        if n==1:\n","            image= image.flip([1])\n","        elif n==2:\n","            image = image.flip([2])\n","        elif n==3:\n","            image = image.transpose(1,2)\n","        elif n==4:\n","            image = image.transpose(1,2).flip([1])\n","        elif n==5:\n","            image = image.transpose(1,2).flip([2])\n","        elif n==6:\n","            image = image.flip([1,2])\n","        elif n==7:\n","            image = image.transpose(1,2).flip([1,2])\n","        return image\n","\n","Sflip = super_flip(8)\n","\n","tr = {\n","    'train': Sflip,\n","    'val': None,\n","    'test': None\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7Qf6WY36-Fo"},"outputs":[],"source":["# Construction des datasets:\n","def oracle(name0, name1, dic):\n","    #load the data:\n","    y0 = dic[name0]['y']\n","    y1 = dic[name1]['y']\n","    \n","    #get the compa:\n","    if y1 < y0:\n","        compa = 0\n","    else:\n","        compa = 1\n","    return compa\n","\n","\n","class Dataset_ordered_pairs(torch.utils.data.Dataset):\n","    def __init__(self, images_dir,  dic, transfo = None):\n","        self.images_dir = images_dir\n","        self.transfo = transfo\n","        self.imgs = ls(images_dir)\n","        self.dic = dic \n","\n","    def __getitem__(self,idx):\n","                \n","        name0 = self.imgs[idx]\n","        name1 = choice(self.imgs)   \n","        label = oracle(name0, name1, self.dic)\n","            \n","        #get the images\n","        path0 = os.path.join(self.images_dir, name0)\n","        img0 =  torch.load(path0)\n","        path1 = os.path.join(self.images_dir, name1)      \n","        img1 = torch.load(path1)\n","\n","        if self.transfo is not None:\n","            img0 = self.transfo(img0)                \n","            img1 = self.transfo(img1)\n","\n","        return img0, img1, torch.from_numpy(np.array(label)).long(), name0, name1   #-1 si pas de classe 0\n","\n","    def __len__(self):\n","        return len(self.imgs) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GI1DH45t7AcN"},"outputs":[],"source":["dataset_train = Dataset_ordered_pairs(dir_images_trainval, dic, tr['train'])\n","dataset_val = Dataset_ordered_pairs(dir_images_trainval, dic, tr['val'])\n","dataset_test = Dataset_ordered_pairs(dir_images_test, dic_test, tr['test'])\n","\n","ds = {'train' : dataset_train , 'val' :dataset_val, 'test':dataset_test }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FiM4F3gaAzw3"},"outputs":[],"source":["# Samplers et loaders\n","train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n","val_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n","\n","samplers={'train':train_sampler,'val':val_sampler}\n","\n","batch_size = 32\n","\n","dataloaders = {x: torch.utils.data.DataLoader(ds[x], batch_size=batch_size, shuffle=False, sampler = samplers[x], num_workers=0) for x in ['train', 'val']}             \n","dataloaders['test'] = torch.utils.data.DataLoader(ds['test'], batch_size=batch_size, shuffle=False, num_workers=0)\n","dataset_sizes = {'train': len(names_train), 'val': len(names_val), 'test': len(names_test)}\n","\n","dataloaders['viz'] = torch.utils.data.DataLoader(ds['train'], batch_size=6, shuffle=False, num_workers=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0Qib3bU7EUO"},"outputs":[],"source":["# Visualisation\n","\n","img1, img2, labels, _, _ = next(iter(dataloaders['test']))\n","\n","fig0 = plt.figure(0, figsize=(16, 2))\n","voir_batch2D(img1, nx = 8, fig = fig0, k=0, min_scale=0,max_scale=10) \n","fig1 = plt.figure(1, figsize=(16, 2))\n","voir_batch2D(img2, nx = 8, fig = fig1, k=0, min_scale=0,max_scale=10) \n","\n","print(labels)\n"]},{"cell_type":"markdown","source":["**Q0** Comment sépare-t-on entraînement et validation ici ? "],"metadata":{"id":"iycy2im3U8wg"}},{"cell_type":"markdown","source":["**Q1** Quel est le rôle de *superf_flip*? Celui de la fonction *oracle* ?"],"metadata":{"id":"3QR_3fcbEBJg"}},{"cell_type":"markdown","source":["**Q2** Les paires d'images sont-elles toutes aussi faciles à ordonner ? "],"metadata":{"id":"Ln7gZSUGEnmU"}},{"cell_type":"markdown","source":["**Exercice n°2** : apprentissage en **siamois**\n","\n","Au cours d'un entraînement, on génère des (batches de) paires d'images comparées. L'entraînement de réseaux **siamois** basique consiste à passer le modèle sur chaque image de la paire indépendemment, puis à pénaliser le modèle lorsque les sorties sont arrangées dans le mauvais ordre.\n","\n","Le plus simple, pour le faire, est de considérer la partie positive de la différence entre les sortie. C'est ce que fait la fonction de coût suivante:"],"metadata":{"id":"hFv2OfMMF1mF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eYZtrZy07G-r"},"outputs":[],"source":["# fonction Hinge Loss\n","\n","def label_to_sgn(label):  #0 -> 1  et 1 -> -1 \n","    sgn =copy.deepcopy(label)\n","    sgn.detach()\n","    sgn[label==0] = 1\n","    sgn[label==1] = -1\n","    return sgn\n","\n","\n","\n","class HingeLoss(torch.nn.Module):\n","    def __init__(self, margin = 0.1):\n","        super(HingeLoss, self).__init__()\n","        self.margin = margin\n","        \n","    def forward(self, output0, output1, label):\n","        sgn = label_to_sgn(label)\n","        diff = sgn*(output1 - output0)\n","        \n","        loss = torch.relu(diff + self.margin).mean()\n","        return loss\n"]},{"cell_type":"markdown","source":["**Q0** Que se passe-t-il si on a des sorties $y_0 > y_1$ alors que le disque de l'image 1 est plus intense que celui de l'image 0 ?\\\n","Dans quels autres cas la fonction de coût est-elle strictement positive ?"],"metadata":{"id":"t2J5EVE3x2OU"}},{"cell_type":"markdown","source":["**Q1** Ecrire la boucle d'apprentissage et lancer sur 20 époques. Garder les justesses successives en mémoire."],"metadata":{"id":"YmVCCdfxUN86"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"04USzeWb7I8m"},"outputs":[],"source":["num_epochs = 20\n","channels = 1 \n","\n","model = vgg11(pretrained=False, progress=True, channels=channels, num_classes=1, init_weights=True)\n","device = torch.device(\"cuda:0\")\n","model = model.to(device) \n","    \n","    \n","criterion = HingeLoss(0.1)\n","optimizer = optim.Adam(model.parameters(), lr = 0.001 )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1wHjBb77Ly5"},"outputs":[],"source":["best_model_wts = copy.deepcopy(model.state_dict())\n","best_acc = 0.0\n","train_accs = []\n","val_accs = []\n","\n","\n","phases = ['train', 'val']\n","\n","for epoch in range(num_epochs):\n","    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","    print('-' * 10)\n","\n","    # Each epoch has a training and validation phase\n","    for phase in phases:\n","        if phase == 'train':\n","            model.train()  # Set model to training mode\n","        else:\n","            model.eval()   # Set model to evaluate mode\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Iterate over data.\n","        for img1, img2, labels, _ , _ in dataloaders[phase]:\n","            img1 = \n","            img2 = \n","            #print(inputs)\n","            labels = labels.to(device).detach()\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward\n","            # track history if only in train\n","            with torch.set_grad_enabled(phase == 'train'):\n","                output1 =\n","                output2 = \n","                preds = \n","#                    loss = torch.mean(output1 - output2)  \n","                loss =  criterion( )\n","\n","                # backward + optimize only if in training phase\n","                if phase == 'train':\n","                    #pass\n","                    loss.backward()\n","                    optimizer.step()\n","           \n","            \n","            # statistics\n","            running_loss += loss.item() * img1.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","            \n","            #del\n","            del img1\n","            del img2\n","            del labels\n","            del loss\n","            del output1\n","            del output2\n","            torch.cuda.empty_cache()\n","            \n","        \n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","            phase, epoch_loss, epoch_acc))\n","\n","        if phase == 'train':\n","          train_accs.append(epoch_acc)\n","\n","        if phase == 'val':\n","          val_accs.append(epoch_acc)\n","\n","        # deep copy the model\n","        if phase == 'val' and epoch_acc > best_acc:\n","            best_acc = epoch_acc\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5P6t_H327OGu"},"outputs":[],"source":["# load best model weights\n","# model.load_state_dict(best_model_wts)"]},{"cell_type":"markdown","source":["**Q3** Visualiser les résultats. La justesse vous paraît-elle une bonne mesure des performances ?"],"metadata":{"id":"MPhXKjr7VW0a"}},{"cell_type":"markdown","metadata":{"id":"mZpLh5fFMzmq"},"source":["**Q4** Comment amélioreriez-vous les performances ?\n","\n","\n","\n"]},{"cell_type":"markdown","source":["**Exercice n°3** RankNet Loss (et ListNet Loss)"],"metadata":{"id":"5Dafc8NUV7Gn"}},{"cell_type":"markdown","source":["Une version plus douce de la Hinge Loss a été très utilisée, en particulier pour l'apprentissage de moteurs de recherche. Il s'agit de la RankNet Loss.\n","\n","Cette fonction de coût est dérivée d'un modèle probabiliste paramétrique, [le modèle de Bradley-Terry](https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model).\n","\n","Dans une version générale, on suppose que le résultat d'une comparaison (ou d'un match) entre deux objets \"0\" et \"1\" (ou deux équipes) est aléatoire, et dépend de réels associés aux objets (les \"niveaux des équipes\") suivant:\n","\\begin{align}\n","P_0 = \\dfrac{f(y_0)}{f(y_0) + f(y_1)}\n","\\tag{1}\n","\\end{align}\n","Où $P_0$ est la probabilité de choisir l'objet \"0\" (ou que la première équipe gagne) et $f$ est une fonction strictement croissante à valeurs positives."],"metadata":{"id":"vrXFNbAtWqva"}},{"cell_type":"markdown","source":["**Q1** Dans le cas où $f(y) = e^{\\sigma y}$, de quoi dépendent les probabilités de choix ?\n","Ecrire la log-vraisemblance de l'événement \"l'objet $x$ est choisi\". "],"metadata":{"id":"HnGSr-f0ZYUe"}},{"cell_type":"markdown","source":["**Q2** En déduire une fonction de coût adaptée à notre problème de ranking."],"metadata":{"id":"06sul9qLaLnt"}},{"cell_type":"markdown","source":["**Q3** Implémenter et comparer sur vingt époques."],"metadata":{"id":"UMHptL6PbLN3"}},{"cell_type":"markdown","metadata":{"id":"139Jz6V4MyfS"},"source":["**Q4** On peut généraliser l'équation (1). Il ne s'agit plus de préférer un objet parmi deux, mais d'ordonner $N$ objets.\n","En déduire une fonction de coût. L' implémenter."]},{"cell_type":"markdown","source":["https://cran.rstudio.com/web/packages/PlackettLuce/vignettes/Overview.html"],"metadata":{"id":"1-WJZbt-dzJ9"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1Ba2cIKvGYTzZDBjdp8y0V1b4fNicpcnk","timestamp":1670587332560},{"file_id":"1O6Bc4hIJh-CyI-vudxxeMS2cxFoLVzS5","timestamp":1670518843991},{"file_id":"1UYLaF5zZauglud-0dOnQv0aGDCT3r8ZD","timestamp":1670452957942},{"file_id":"12YrKxCuPsuJo2PuZiUA4bw5FhhXy_X37","timestamp":1669935793550},{"file_id":"1EdCq8OdFztPUCVOYYsTpVvWbrloBa1YK","timestamp":1669903486590},{"file_id":"1uuAC25WpowNFFlmwcwb-w6pXdPirvtKo","timestamp":1669347264899},{"file_id":"1jxAGXknXdmA31l0X_7u9hMTmIQsIhCqi","timestamp":1669279686108},{"file_id":"1pspw1Siokq2mYd_m4nlQzaScfy_tmAi4","timestamp":1642630965738}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}