{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1cATxIfGcEJ1MisIeMGpmm4y4oUgfRr2O","timestamp":1642738269364}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9Jp87bbda7qc"},"source":["**Partie III**\n","\n","Maintenant qu'on a vu les briques de base, nous allons entraîner un réseau de neurones à couches de convolution (acronyme CNN) sur un problème un peu plus compliqué que la séparation des nuages de points: la reconnaissance des chiffres manuscrits. \\\\"]},{"cell_type":"code","metadata":{"id":"Ey8X57M8i5Yj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666281895229,"user_tz":-120,"elapsed":22666,"user":{"displayName":"pierre lepetit","userId":"00153244657746066434"}},"outputId":"c675c1e2-6b52-4398-8702-a6f476f1e13c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"eN2o2vVtaHcE"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","import torch\n","import torchvision\n","import torch.nn as nn   \n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, models, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-6auA4Cc6xC"},"source":["Le jeu de données s'appelle MNIST. Il est dans le dossier partagé. Il comporte des images noir et blanc (1 canal) de 28*28 pixels. \\\\\n","\n","Un objet dataset spécifique lui ait consacré dans le module torchvision.datasets. Les cellules suivantes permettent d'afficher quelques images :"]},{"cell_type":"code","metadata":{"id":"MyYZ8PBCan6c"},"source":["root = '/content/drive/MyDrive/TP_ENM/data'\n","#root = '/content/drive/Shareddrives/TP_ENM/data'\n","\n","#transformation (mise au format)\n","tr=torchvision.transforms.Compose([\n","   torchvision.transforms.ToTensor(),\n","   torchvision.transforms.Normalize((0.1307,), (0.3081,))\n","   ])\n","\n","#Définition des jeux d'apprentissage:\n","ds = {'train': torchvision.datasets.MNIST(root, train = True, transform = tr,\n","                                          download=True),\n","      'val': torchvision.datasets.MNIST(root, train = False, transform = tr,\n","                                        download=True)\n","     }\n","\n","phases = ['train','val']\n","\n","#Dataloaders:\n","bs = 8\n","loader ={x :  DataLoader(ds[x], batch_size=bs, shuffle=True, num_workers = 4) for x in phases}\n","#pour accélérer l'apprentissage, on a passé: num_workers = 4 \n","#(le chargement des données est ainsi parallélisé, pour aller encore plus vite, on utilisera une carte gpu -voir partie IV)\n","\n","#Tailles (pour le calcul des scores)\n","dataset_sizes = {x: len(ds[x]) for x in  phases}\n","\n","#On fige le générateur de nombres aléatoires\n","random_seed = 1\n","torch.manual_seed(random_seed)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJ5jwbPKarBT"},"source":["x, t = next(iter(loader['train']))\n","\n","print(x.shape)\n","\n","fig = plt.figure()\n","for i in range(8):\n","  plt.subplot(4,2,i+1)\n","  plt.tight_layout()\n","  plt.imshow(x[i,0,:,:], cmap='gray') #, interpolation='none')\n","  plt.title(\"Ground Truth: {}\".format(t[i]))\n","  plt.xticks([])\n","  plt.yticks([])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XWHzA-82fq_7"},"source":["Nous allons définir maintenant un CNN de faible profondeur (deux couches de convolution).\n","\n","**Exercice:** Déterminer *N* de façon à ce que le réseau accepte en entrée les images de MNIST."]},{"cell_type":"code","metadata":{"id":"BRQ6P0duauRr"},"source":["N = ...\n","\n","\n","class CNN(nn.Module):\n","    \n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, padding =2)\n","        self.conv2 = nn.Conv2d(10, 15, kernel_size=5, padding =2)\n","        self.fc1 = nn.Linear(N, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = x.view(-1, N)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        # ici, le log est appliqué derrière la softmax :\n","        return F.log_softmax(x, dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_GdrC04hvjL"},"source":["model = CNN()\n","\n","#optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","\n","# on sélectionne les log vraisemblances pour les vraies classes:\n","loss_fn =  torch.nn.NLLLoss() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zP49HEuzhu8k"},"source":["La boucle d'apprentissage est doublée: on ne met à jour les poids que dans la première partie, consacrée à l'entraînement. Pendant la **validation**, on surveille les performances en généralisation sur des images indépendantes :\n"]},{"cell_type":"code","metadata":{"id":"zkrHQYLraw0m"},"source":["import time\n","t = time.time()\n","\n","train_losses = []\n","val_losses = []\n","\n","train_accs = []\n","val_accs = []\n","\n","# boucle d'apprentissage:\n","for epoch in range(6):\n","    print('epoch :' + str(epoch))\n","    \n","    running_loss_train = 0.\n","    running_corrects_train = 0.\n","    running_loss_val = 0.\n","    running_corrects_val = 0.\n","    \n","    # entraînement\n","    for x, label in loader['train']:\n","        optimizer.zero_grad()\n","        output = model(x)\n","        l = loss_fn(output, label)\n","        l.backward()     \n","        optimizer.step()\n","\n","        #prédictions:\n","        _, preds = torch.max(output, 1)\n","\n","        # compteurs\n","        running_loss_train += l.item() * x.shape[0]\n","        running_corrects_train += torch.sum(preds == label.data)\n","\n","    # calcul et stockage des scores d'entraînement\n","\n","    epoch_loss_train = running_loss_train / dataset_sizes['train']\n","    epoch_acc_train = running_corrects_train.float() / dataset_sizes['train']  \n","\n","    #Stockage : à coder\n","\n","    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","        'train', epoch_loss_train, epoch_acc_train))\n","\n","\n","    # validation\n","    model.eval()\n","\n","    for x, label in loader['val']:\n","                \n","        with torch.no_grad():\n","            output = model(x)\n","            l = loss_fn(output, label)        \n","            \n","        # prédictions:\n","        _, preds = torch.max(output, 1)\n","\n","        # compteurs:\n","        running_loss_val += l.item() * x.shape[0]\n","        running_corrects_val += torch.sum(preds == label.data)\n","    \n","    # calcul et stockage des scores en validation\n","    epoch_loss_val = running_loss_val / dataset_sizes['val']\n","    epoch_acc_val = running_corrects_val.float() / dataset_sizes['val']    \n","\n","    #Stockage : à coder\n","\n","    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","        'val', epoch_loss_val, epoch_acc_val))\n","\n","    new_t = time.time()\n","    print('time ' +str(round(new_t- t)))\n","    t = new_t\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hznaWQbLoJQD"},"source":["**Exercice**: A chaque époque, stocker la justesse (*accuracy*) et la valeur de la fonction de coût dans les listes train_losses, val_losses,\n","train_accs et val_accs. \\\\\n","Tracer les **courbes d'apprentissage** sur six époques."]},{"cell_type":"markdown","metadata":{"id":"LPJ1inr0ru_9"},"source":["**Exercice:** Reprendre le perceptron à deux couches (*fc1* et *fc2*) du réseau précédent et le modifier pour prendre directement les imagettes de MNIST en entrée. \n","Comparer le perceptron seul au CNN en termes de taille (nombre de poids) et de performances."]}]}