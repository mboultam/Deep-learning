{"cells":[{"cell_type":"markdown","metadata":{"id":"MSgiKnAs1BbN"},"source":["**TP n°4** : Deep Learning pour le clustering en grande dimension"]},{"cell_type":"markdown","metadata":{"id":"AvaKH1dZvg2B"},"source":["#Plan\n","\n","##Partie I:\n","\n","Rappels sur le clustering:\n","- k-moyennes , un rapide rappel\n","- problème non-linéaire - espace de redescription\n","- les limites de la grande dimension\n","\n","##Partie II:\n","\n","- réduire la dimensionnalité avec un auto-encodeur\n","- séparer linéairement avec un auto-encodeur variationnel\n","\n","\n","Durée : 2 h"]},{"cell_type":"markdown","metadata":{"id":"P1waEt7NJgSx"},"source":["**Partie II** : Partionnement dans l'espace latent d'un autoencodeur\n","\n","Dans la première partie, on a présenté sur des exemples \"naïfs\" quelques limites génériques des méthodes de partitionnement. Avec des données images, ces limites sont atteintes : \n","- regrouper selon les \"contenus\" est un problème profondément non-linéaire\n","- une description de l'image dans un espace de plus petite dimension est possible dans la mesure où le nombre de degrés de liberté des objets contenus par l'image est restreint.\n","\n","Dans cette partie, on voit comment avec un \"auto-encodeur\", on peut construire un espace de redescription -l'espace latent- où le partionnement devient facile. Cette possibilité est illustrée sur le jeu de données MNIST.\n","L'**exercice 1** présente une méthode de réduction de la dimensionnalité par réseaux de neurones: l'auto-encodeur. A partir d'une achitecture simplifiée, nous visualisons la façon dont le signal s'organise au niveau de la \"couche latente\". Nous vérifions qu'effectivement, des clusters se forment et qu'il correspondent plus ou moins aux différents chiffres. Dans la suite suite, on cherche à améliorer ce résultat. \\\n","Dans l'**exercice 2**, on présente le concept d'auto-encodeur variationnel (vae). Un premier exemple vient illustrer comment, avec un vae, on peut contraindre l'organisation de l'espace latent. \\\n","Dans l'**exercice 3**, un VAE mieux adapté au problème de clustering est présenté. Converti en classifieur (approche transductive), il permet d'atteindre des justesses de plus de 90% sur le jeu de test des chiffres de MNIST sans l'aide d'aucune cible (sauf pour identifier les clusters).  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fexoQ5AdbLQ-"},"outputs":[],"source":["import torch; torch.manual_seed(0)\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch.utils\n","import torch.distributions\n","import torchvision\n","import numpy as np\n","import matplotlib.pyplot as plt \n","import matplotlib.cm as cm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5Rk7il7bLN2"},"outputs":[],"source":["device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('drive/MyDrive/TP_ENM_2223')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRVCqpVWSpxc","executionInfo":{"status":"ok","timestamp":1669979648864,"user_tz":-180,"elapsed":5280,"user":{"displayName":"pierre lepetit","userId":"00153244657746066434"}},"outputId":"707efb8c-b354-4593-d279-f13d98f87a2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4oYsWzzQbK46"},"outputs":[],"source":["train_set = torchvision.datasets.MNIST('./data',\n","                 transform=torchvision.transforms.ToTensor(),\n","                 train=True,\n","                 download=True)\n","\n","test_set = torchvision.datasets.MNIST('./data',\n","                 transform=torchvision.transforms.ToTensor(),\n","                 train=False,\n","                 download=True)\n","\n","train_loader = DataLoader(train_set,\n","                         batch_size=128,\n","                         shuffle=True)\n","\n","test_loader = DataLoader(test_set,\n","                         batch_size=128,\n","                         shuffle=True)"]},{"cell_type":"markdown","source":["**Exercice 1** Un premier autoencodeur\n","\n","Dans la suite, on considère un espace d'images $\\mathcal{X}$, et un large échantillon d'images $x^{(i)}$ prises dans $\\mathcal{X}$. \n","Un auto-encodeur est un couple de deux réseaux de neurones $f_{\\phi}, g_\\theta$ \n","que l'on entraîne simultanément à une tâche triviale: restituer le signal mis d'entrée. On cherche ainsi, le plus souvent, à minimiser :\n","\n","$$ \\mathcal{L}(\\theta , \\phi, X) =  \\mathbb{E} {\\bigg [}\\: ||g_{\\theta} ( f_{\\phi} (X)) - X ||^2 {\\bigg ]} $$\n","\n","L'intérêt vient du fait que l'espace de sortie de $f_{\\phi}$, qu'on appelle \"espace latent\", est de dimension réduite. Pour favoriser au mieux la reconstruction, $f_{\\phi}$ doit \"encoder\" l'information utile dans l'espace latent, tandis que $g_{\\theta}$ doit la décoder.\n","On peut ainsi espérer réduire la dimension d'un problème de partionnement.\n"],"metadata":{"id":"ezLjUIFcAU8W"}},{"cell_type":"markdown","source":["**Q1** Les codes suivants permettent de construire des auto-encodeurs comprenant plus ou moins de couches cachées et un espace latent de dimension (*latent_dims*) plus ou moins grande. \\\n","Vous pouvez étudier trois aspects:\n","- est-ce que l'apprentissage a bien convergé ? Y a-t-il surraprentissage ?\n","- est-ce que l'espace latent est organisé ? En particulier, voit-on des clusters ? Le K-Means est-il efficace dessus ? (La TSNE permettra de visualiser l'organisation de l'espace latent en grande dimension). \\\\\n","- peut-on se servir de $g_\\theta$ comme un modèle génératif ?  \n","\n","\n","rq : https://fr.wikipedia.org/wiki/Courbe_de_Peano"],"metadata":{"id":"K02__LtWgVI6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ghl_mTHgbLKr"},"outputs":[],"source":["class ShallowEncoder(nn.Module):\n","    def __init__(self, latent_dims):\n","        super(ShallowEncoder, self).__init__()\n","        self.linear1 = nn.Linear(784, 512)\n","        self.linear2 = nn.Linear(512, latent_dims)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.linear1(x))\n","        return self.linear2(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxkj5vXrbLFu"},"outputs":[],"source":["class ShallowDecoder(nn.Module):\n","    def __init__(self, latent_dims):\n","        super(ShallowDecoder, self).__init__()\n","        self.linear1 = nn.Linear(latent_dims, 512)\n","        self.linear2 = nn.Linear(512, 784)\n","\n","    def forward(self, z):\n","        z = F.relu(self.linear1(z))\n","        z = torch.sigmoid(self.linear2(z))\n","        return z.reshape((-1, 1, 28, 28))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-MKkfQA7bK-a"},"outputs":[],"source":["class ShallowAutoencoder(nn.Module):\n","    def __init__(self, latent_dims):\n","        super(ShallowAutoencoder, self).__init__()\n","        self.encoder = ShallowEncoder(latent_dims)\n","        self.decoder = ShallowDecoder(latent_dims)\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yryPoacHbK7Z"},"outputs":[],"source":["def train(autoencoder, data, epochs=20):\n","    opt = torch.optim.Adam(autoencoder.parameters())\n","    for epoch in range(epochs):\n","        print(f\"epoch : {epoch+1}/{epochs}\")\n","        epoch_loss = 0.\n","        for i, (x, y) in enumerate(train_loader):\n","            x = x.to(device) # GPU\n","            opt.zero_grad()\n","            x_hat = autoencoder(x)\n","            loss = ((x - x_hat)**2).mean()\n","            loss.backward()\n","            opt.step()\n","            epoch_loss += loss.item()\n","        print(f\"epoch loss : {epoch_loss:.3f}\")\n","    return autoencoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"INdDMHifMbba"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim=784, inter_dims=[500,500,2000], latent_dims=10):\n","        super(Encoder,self).__init__()\n","\n","        self.encoder=nn.Sequential(\n","            nn.Linear(input_dim, inter_dims[0]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[0], inter_dims[1]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[1], inter_dims[2]),\n","            nn.ReLU(True)\n","        )\n","\n","        self.mu_l=nn.Linear(inter_dims[-1], latent_dims)\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, start_dim=1)\n","        e = self.encoder(x)\n","\n","        mu = self.mu_l(e)\n","\n","        return mu \n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, input_dim=784, inter_dims=[500,500,2000], latent_dims=10):\n","        super(Decoder,self).__init__()\n","\n","        self.decoder=nn.Sequential(\n","            nn.Linear(latent_dims, inter_dims[-1]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[-1], inter_dims[-2]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[-2], inter_dims[-3]),\n","            nn.ReLU(True),            \n","            nn.Linear(inter_dims[-3], input_dim),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, z):\n","        x = self.decoder(z)\n","        return x.reshape((-1, 1, 28, 28))\n","\n","class Autoencoder(nn.Module):\n","    def __init__(self, latent_dims):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = Encoder(latent_dims=latent_dims)\n","        self.decoder = Decoder(latent_dims=latent_dims)\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lBdp6avbt3Q"},"outputs":[],"source":["def plot_latent(autoencoder, data, num_batches=100):\n","    for i, (x, y) in enumerate(data):\n","        z = autoencoder.encoder(x.to(device))\n","        z = z.to('cpu').detach().numpy()\n","        plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10', s=1)\n","        if i > num_batches:\n","            plt.colorbar()\n","            break\n","\n","\n","def plot_latent_3d(autoencoder, data, num_batches=5):\n","    fig = plt.figure()\n","    ax = fig.add_subplot(projection='3d')\n","    ax.set_xlabel('Z[0]')\n","    ax.set_ylabel('Z[1]')\n","    ax.set_zlabel('Z[2]')\n","    for i, (x, y) in enumerate(data):\n","        z = autoencoder.encoder(x.to(device))\n","        z = z.to('cpu').detach().numpy()\n","        d = ax.scatter(z[:, 0], z[:, 1], z[:, 2], c=y, cmap='tab10', s=2)\n","\n","        if i > num_batches:\n","            fig.colorbar(d)\n","            break\n","    return ax\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCou7CGAbtxd"},"outputs":[],"source":["def plot_reconstructed(autoencoder, r0=(-3, 3), r1=(-3, 3), n=12):\n","    w = 28\n","    img = np.zeros((n*w, n*w))\n","    for i, y in enumerate(np.linspace(*r1, n)):\n","        for j, x in enumerate(np.linspace(*r0, n)):\n","            z = torch.Tensor([[x, y, 0]]).to(device)\n","            x_hat = autoencoder.decoder(z)\n","            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n","            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n","    plt.imshow(img, extent=[*r0, *r1])\n"]},{"cell_type":"markdown","source":["Avec un espace latent de dimension 10:"],"metadata":{"id":"nWKhufPXgK49"}},{"cell_type":"code","source":["latent_dims = 10\n","# autoencoder = ShallowAutoencoder(latent_dims).to(device) \n","autoencoder = Autoencoder(latent_dims).to(device) \n","autoencoder = train(autoencoder, train_loader)"],"metadata":{"id":"mujDfaeJiHWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_reconstructed_d10(autoencoder, r0=(-3, 3), r1=(-3, 3), n=12):\n","    w = 28\n","    img = np.zeros((n*w, n*w))\n","    for i, y in enumerate(np.linspace(*r1, n)):\n","        for j, x in enumerate(np.linspace(*r0, n)):\n","            z = torch.Tensor([[x, y] + [0 for i in range(8)]]).to(device)\n","            x_hat = autoencoder.decoder(z)\n","            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n","            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n","    plt.imshow(img, extent=[*r0, *r1])"],"metadata":{"id":"2J3jlRTSj5gC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Q2** Lorsque l'espace latent est de taille plus grande, il n'est plus possible d'en cerner l'organisation. Un outil permet alors de plonger l'espace latent dans le plan en conservant la relation de proximité: c'est la [t-SNE](https://distill.pub/2016/misread-tsne/).\n","L'utiliser pour évaluer l'organisation en clusters dans l'espace latent."],"metadata":{"id":"Ff4jOkk6lSQb"}},{"cell_type":"code","source":["from sklearn.manifold import TSNE"],"metadata":{"id":"VQ13RaA4ncPA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plotTSNE(model, dataset, size=100, perplexity=30, n_iter=1000):\n","  model.eval() \n","  z = np.array([])\n","  first = True\n","  dataLoader = DataLoader(dataset, batch_size=128, shuffle=False,\n","                          num_workers=2)    \n","  it=iter(dataLoader)\n","\n","  if size is None:\n","      size=len(dataLoader)\n","\n","  # Calcul des vecteurs latents z\n","  nbreImgCount=0\n","  while(1):\n","          try :\n","              tmp=next(it)\n","          except:\n","              break    \n","          \n","          labels_batch = tmp[1]\n","          imgs = tmp[0]\n","          \n","          imgs = imgs.cuda()\n","          z_batch = model.encoder(imgs)  # plong. dans l'espace latent\n","          # z_batch = torch.flatten(imgs, start_dim = 1) # si l'on veut tsne brute\n","          z_batch = z_batch.cpu().detach().numpy()\n","          \n","          if len(z) == 0:\n","              z = z_batch\n","              labels = labels_batch\n","\n","          else:\n","              z = np.concatenate((z,z_batch),axis=0)\n","              labels = np.concatenate((labels,labels_batch))\n","              \n","              \n","          nbreImgCount += len(imgs)\n","          print(nbreImgCount)\n","          if nbreImgCount >=size:\n","              break\n","\n","  print('Dim vecteurs espace latent : {}',z.shape[1])\n","\n","  # Calcul de la TSNE en 2D\n","\n","  X2 = TSNE(n_components=2,\n","            verbose=2,\n","            init='pca',\n","            n_iter=n_iter,\n","            perplexity=perplexity).fit_transform(z)\n","\n","  b=((labels-labels.min())/(labels.max()-labels.min())*255.).astype(int)\n","  c1 = cm.jet(b)\n","\n","  fig=plt.figure('TSNE 2D ')\n","\n","  for i,label in enumerate(labels):\n","      plt.text(X2[i, 0], X2[i, 1],str(label),color=c1[i],fontsize=12)\n","      \n","  plt.xlabel('X')\n","  plt.ylabel('Y')\n","  plt.axis([-50,50,-50,50])     "],"metadata":{"id":"vl6xTgrDmEVJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = autoencoder \n","dataset = test_set  \n","size = 1000\n","n_iter = 1000\n","perplexity = 20\n","size= 1000\n","\n","plt.rcParams['figure.dpi'] = 200\n","plotTSNE(model, dataset, size=1000, perplexity=perplexity, n_iter=n_iter)\n"],"metadata":{"id":"SbENWR9RpMUp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Q3** Pour évaluer le partionnement par K-moyennes sur l'esapce latent, on peut exploiter la matrice de confusion. Moyennant une juste assignation des classes à chacun des clusters, on peut calculer une justesse. La déterminer à partir des codes ci-dessous."],"metadata":{"id":"uSMPml5775ri"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.mixture import GaussianMixture\n","  \n","Z = []\n","Y = []\n","with torch.no_grad():\n","    for x, y in test_loader:\n","        x = x.cuda()\n","        z1 = autoencoder.encoder(x)\n","        Z.append(z1)\n","        Y.append(y)\n","\n","Z = torch.cat(Z, 0).detach().cpu().numpy()\n","Y = torch.cat(Y, 0).detach().numpy()\n","\n","pre = KMeans(n_clusters=10).fit_predict(Z)\n","gmm = GaussianMixture(n_components=10, covariance_type='diag')\n","pre2 = gmm.fit_predict(Z)\n","\n","\n","plt.figure('matrice confusion kmeans')\n","c = confusion_matrix(Y, pre)\n","plt.imshow(c)\n","plt.colorbar()"],"metadata":{"id":"le9qLEJg05eo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pour [trouver la permutation](https://en.wikipedia.org/wiki/Assignment_problem) qui maximise la justesse: le module linear_assignment, mis à disposition dans le drive. Ainsi chaque cluster est assigné à une classe."],"metadata":{"id":"JOdNAVfH8kbg"}},{"cell_type":"code","source":["from linear_assignment_ import linear_assignment"],"metadata":{"id":"KyoRME2HTAoE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cluster_acc(Y_pred, Y):\n","    D = max(Y_pred.max(), Y.max())+1\n","    w = np.zeros((D,D), dtype=np.int64)\n","    for i in range(Y_pred.size):\n","        w[Y_pred[i], Y[i]] += 1\n","    ind = linear_assignment(w.max() - w)\n","    return sum([w[i,j] for i,j in ind])/Y_pred.size, w"],"metadata":{"id":"cJhw6KuJ73DQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Conclusion**: \n","\n","Avec un outillage standard (perceptrons multicouches + optim ADAM) les auto-encodeurs convergent sans difficulté.\n","L'espace latent d'un autoencodeur est organisé, les populations associées à chaque chiffre y forment des clusters plus ou moins nets.\\\n","La séparation avec la TSNE est manifeste (nettement plus qu'avec les données brutes), mais un partitionnement sur l'espace latent avec des méthodes traditionnelles n'est pas très efficace: la justesse après réassignation n'atteint que 70% (certes, avec un nombre limité d'époques et sans chercher à tuner le réseau).\n","\n","Néanmoins, ce chiffre est déjà remarquable. Noter que nous n'avons pas utilisé une seule cible pendant la phase d'entraînement. "],"metadata":{"id":"rqRTDZrFyFM3"}},{"cell_type":"markdown","source":["**Exercice 2** Un autoencodeur variationnel\n","\n","Pour améliorer les propriétés de l'espace latent, l'autoencodeur \"variationnel\" \n","a donné des résultats prometteurs.\n","Dans cet exercice, on décrit une version simple de ce modèle en termes pratiques. Mais il faut garder à l'esprit que ce modèle découle d'un cadre conceptuel profond. \n","\n","On pourra consulter les articles suivants avant de lire le code suivant.\n","- [un post](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73) pour un public plus branché \"info\"\n","- [l'article \"séminal\"](https://arxiv.org/pdf/1312.6114v10.pdf) de D.Kingma (se concentrer sur l'intro).\n","\n"],"metadata":{"id":"Tn8GbwrA_EDU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xCz8dqzbtvL"},"outputs":[],"source":["#Un premier VAE avec quelques couches complètement connectées\n","\n","class ShallowVariationalEncoder(nn.Module):\n","    def __init__(self, latent_dims):\n","        super(ShallowVariationalEncoder, self).__init__()\n","        self.linear1 = nn.Linear(784, 512)\n","        self.linear2 = nn.Linear(512, latent_dims)\n","        self.linear3 = nn.Linear(512, latent_dims)\n","\n","        self.N = torch.distributions.Normal(0, 1)\n","        self.N.loc = self.N.loc.cuda() \n","        self.N.scale = self.N.scale.cuda()\n","        self.kl = 0\n","\n","    def forward(self, x):\n","        x = torch.flatten(x, start_dim=1)\n","        x = F.relu(self.linear1(x))\n","        mu =  self.linear2(x)\n","        sigma = torch.exp(self.linear3(x))\n","        z = mu + sigma*self.N.sample(mu.shape)\n","        #Div de KL entre Nz et N01:\n","        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n","        return z\n","\n","class ShallowVariationalAutoencoder(nn.Module):\n","    def __init__(self, latent_dims):\n","        super(ShallowVariationalAutoencoder, self).__init__()\n","        self.encoder = ShallowVariationalEncoder(latent_dims)\n","        self.decoder = ShallowDecoder(latent_dims)\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z)\n"]},{"cell_type":"markdown","source":["**Q1** Quelles sont les différences avec l'AE classique ?\n","Quels rôles jouent les termes $\\mu$, $\\sigma$ et l'attribut *self.kl* ?"],"metadata":{"id":"5r-Q94xnF1k1"}},{"cell_type":"markdown","source":["**Q2** Reprendre la fonction *train* et l'adapter à l'autoencodeur de façon à forcer la distribution sur la couche latente à suivre une loi normale centrée réduite."],"metadata":{"id":"P9d_bmBVGmQu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gHnGseRdWzz"},"outputs":[],"source":["# Boucle d'apprentissage\n","def train(autoencoder, data, epochs=20):\n","    opt = torch.optim.Adam(autoencoder.parameters())\n","    for epoch in range(epochs):\n","        print(f\"epoch : {epoch+1}/{epochs}\")\n","        epoch_loss = 0.\n","        for x, y in data:\n","            x = x.to(device)\n","            opt.zero_grad()\n","            x_hat = autoencoder(x)\n","            # C'est la fonction de coût \"ELBO\" (très populaire depuis [Kingma14])\n","            loss = ((x - x_hat)**2).sum() + autoencoder.encoder.kl\n","            loss.backward()\n","            opt.step()\n","            epoch_loss += loss.item()\n","        print(f\"epoch loss : {epoch_loss/len(data):.2f}\")\n","    return autoencoder\n"]},{"cell_type":"markdown","source":["**Q3** Visualiser les quelques résultats, la répartition des images dans l'espace latent en 2/10 dimensions. Evaluer le réseau en matière de partionnement."],"metadata":{"id":"6UY7UWjlLqh-"}},{"cell_type":"code","source":["def plot_reconstructed_vae(autoencoder, r0=(-3, 3), r1=(-3, 3), n=12):\n","    w = 28\n","    img = np.zeros((n*w, n*w))\n","    for i, y in enumerate(np.linspace(*r1, n)):\n","        for j, x in enumerate(np.linspace(*r0, n)):\n","            z = torch.Tensor([[x, y]]).to(device)\n","            x_hat = autoencoder.decoder(z)\n","            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n","            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n","    plt.imshow(img, extent=[*r0, *r1])"],"metadata":{"id":"h8w2KgvNKG1T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Q4** Les VAE sont surtout connus pour être concurrents du GAN. En quoi est-ce une approche générative ? Illustrer."],"metadata":{"id":"w03rs7pV0uE8"}},{"cell_type":"markdown","source":["**Exercice 3** \n","Cet exercice présente une version du VAE adaptée à un clustering sur couches latente qui faisait [l'état de l'art en 2017](https://www.ijcai.org/proceedings/2017/0273.pdf).\n","\n","La méthode consiste simplement à forcer la proximité avec un [modèle de mélange gaussien](https://fr.wikipedia.org/wiki/Mod%C3%A8le_de_m%C3%A9lange_gaussien).\n","\n","Ici, l'énoncé est encore plus ouvert : faire tourner le modèle et évaluer ses performances en matière de clustering, de classification et de génération d'images."],"metadata":{"id":"b_DmZGyACcLo"}},{"cell_type":"code","source":["import torch\n","from torchvision.datasets import MNIST\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader,TensorDataset\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('drive/MyDrive/TP_dev')\n","from linear_assignment_ import linear_assignment"],"metadata":{"id":"CAFGbgW0w9CP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train=MNIST(root=data_dir,train=True,download=True)\n","test=MNIST(root=data_dir,train=False,download=True)\n","\n","X=torch.cat([train.data.float().view(-1,784)/255.,test.data.float().view(-1,784)/255.],0)\n","Y=torch.cat([train.targets,test.targets],0)"],"metadata":{"id":"1d7Szd5I83sX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dFvF2jRbtmI"},"outputs":[],"source":["def get_mnist(data_dir='./data/mnist/',batch_size=128):\n","    train=MNIST(root=data_dir,train=True,download=True)\n","    test=MNIST(root=data_dir,train=False,download=True)\n","\n","    X=torch.cat([train.data.float().view(-1,784)/255.,test.data.float().view(-1,784)/255.],0)\n","    Y=torch.cat([train.targets,test.targets],0)\n","\n","    dataset=dict()\n","    dataset['X']=X\n","    dataset['Y']=Y\n","\n","    dataloader=DataLoader(TensorDataset(X,Y),batch_size=batch_size,shuffle=True,num_workers=4)\n","\n","    return dataloader,dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rYQMjaYMvHuB"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from torch.optim import Adam\n","import itertools\n","from sklearn.mixture import GaussianMixture\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import os\n","\n","\n","def cluster_acc(Y_pred, Y):\n","    # from sklearn.utils.linear_assignment_ import linear_assignment\n","    assert Y_pred.size == Y.size\n","    D = max(Y_pred.max(), Y.max())+1\n","    w = np.zeros((D,D), dtype=np.int64)\n","    for i in range(Y_pred.size):\n","        w[Y_pred[i], Y[i]] += 1\n","    ind = linear_assignment(w.max() - w)\n","    return sum([w[i,j] for i,j in ind])*1.0/Y_pred.size, w\n","\n","\n","def block(in_c,out_c):\n","    layers=[\n","        nn.Linear(in_c,out_c),\n","        nn.ReLU(True)\n","    ]\n","    return layers\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim=784, inter_dims=[500,500,2000], latent_dims=10):\n","        super(Encoder,self).__init__()\n","\n","        self.encoder=nn.Sequential(\n","            nn.Linear(input_dim, inter_dims[0]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[0], inter_dims[1]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[1], inter_dims[2]),\n","            nn.ReLU(True)\n","        )\n","\n","        self.mu_l=nn.Linear(inter_dims[-1], latent_dims)\n","        self.log_sigma2_l=nn.Linear(inter_dims[-1],hid_dim)\n","\n","    def forward(self, x):\n","        # x = torch.flatten(x, start_dim=1)\n","        e = self.encoder(x)\n","\n","        mu = self.mu_l(e)\n","        log_sigma2=self.log_sigma2_l(e)\n","\n","        return mu, log_sigma2\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, input_dim=784, inter_dims=[500,500,2000], latent_dims=10):\n","        super(Decoder,self).__init__()\n","\n","        self.decoder=nn.Sequential(\n","            nn.Linear(latent_dims, inter_dims[-1]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[-1], inter_dims[-2]),\n","            nn.ReLU(True),\n","            nn.Linear(inter_dims[-2], inter_dims[-3]),\n","            nn.ReLU(True),            \n","            nn.Linear(inter_dims[-3], input_dim),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, z):\n","        x = self.decoder(z)\n","        return x #.reshape((-1, 1, 28, 28))\n","\n","class Autoencoder(nn.Module):\n","    def __init__(self, latent_dims):\n","        super(Autoencoder, self).__init__()\n","        self.encoder = Encoder(latent_dims=latent_dims)\n","        self.decoder = Decoder(latent_dims=latent_dims)\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z)\n","\n","\n","\n","\n","class VaDE(nn.Module):\n","    def __init__(self,args):\n","        super(VaDE,self).__init__()\n","        self.encoder=Encoder()\n","        self.decoder=Decoder()\n","\n","        self.pi_=nn.Parameter(torch.FloatTensor(args.nClusters,).fill_(1)/args.nClusters,requires_grad=True)\n","        self.mu_c=nn.Parameter(torch.FloatTensor(args.nClusters,args.hid_dim).fill_(0),requires_grad=True)\n","        self.log_sigma2_c=nn.Parameter(torch.FloatTensor(args.nClusters,args.hid_dim).fill_(0),requires_grad=True)\n","\n","        self.args=args\n","\n","\n","    def pre_train(self, dataloader, pre_epoch=10):\n","\n","        if  not os.path.exists('./pretrain_model.pk'):\n","\n","          Loss=nn.MSELoss()\n","          opti=Adam(itertools.chain(self.encoder.parameters(),self.decoder.parameters()))\n","\n","          print('Pretraining......')\n","          epoch_bar=tqdm(range(pre_epoch))\n","          for _ in epoch_bar:\n","              L=0\n","              for x,y in dataloader:\n","                  if self.args.cuda:\n","                      x = x.cuda()\n","\n","                  z, _ = self.encoder(x)\n","                  x_ = self.decoder(z)\n","                  loss = Loss(x,x_)\n","\n","                  L += loss.detach().cpu().numpy()\n","\n","                  opti.zero_grad()\n","                  loss.backward()\n","                  opti.step()\n","\n","              epoch_bar.write('L2={:.4f}'.format(L/len(dataloader)))\n","\n","          self.encoder.log_sigma2_l.load_state_dict(self.encoder.mu_l.state_dict())\n","\n","          Z = []\n","          Y = []\n","          with torch.no_grad():\n","              for x, y in dataloader:\n","                  if self.args.cuda:\n","                      x = x.cuda()\n","\n","                  z1, z2 = self.encoder(x)\n","                  assert F.mse_loss(z1, z2) == 0\n","                  Z.append(z1)\n","                  Y.append(y)\n","\n","          Z = torch.cat(Z, 0).detach().cpu().numpy()\n","          Y = torch.cat(Y, 0).detach().numpy()\n","\n","          gmm = GaussianMixture(n_components=self.args.nClusters, covariance_type='diag')\n","\n","          pre = gmm.fit_predict(Z)\n","          print('Acc={:.4f}%'.format(cluster_acc(pre, Y)[0] * 100))\n","\n","          self.pi_.data = torch.from_numpy(gmm.weights_).cuda().float()\n","          self.mu_c.data = torch.from_numpy(gmm.means_).cuda().float()\n","          self.log_sigma2_c.data = torch.log(torch.from_numpy(gmm.covariances_).cuda().float())\n","\n","          torch.save(self.state_dict(), './pretrain_model.pk')\n","\n","        else:\n","            self.load_state_dict(torch.load('./pretrain_model.pk'))\n","\n","\n","    def predict(self,x):\n","        z_mu, z_sigma2_log = self.encoder(x)\n","        z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu\n","        pi = self.pi_\n","        log_sigma2_c = self.log_sigma2_c\n","        mu_c = self.mu_c\n","        yita_c = torch.exp(torch.log(pi.unsqueeze(0))+self.gaussian_pdfs_log(z,mu_c,log_sigma2_c))\n","\n","        yita=yita_c.detach().cpu().numpy()\n","        return np.argmax(yita,axis=1)\n","\n","\n","    def ELBO_Loss(self,x,L=1):\n","        det=1e-10\n","\n","        L_rec=0\n","\n","        z_mu, z_sigma2_log = self.encoder(x)\n","        for l in range(L):\n","\n","            z=torch.randn_like(z_mu)*torch.exp(z_sigma2_log/2)+z_mu\n","\n","            x_pro=self.decoder(z)\n","\n","            L_rec+=F.binary_cross_entropy(x_pro,x)\n","\n","        L_rec/=L\n","\n","        Loss=L_rec*x.size(1)\n","\n","        pi=self.pi_\n","        log_sigma2_c=self.log_sigma2_c\n","        mu_c=self.mu_c\n","\n","        z = torch.randn_like(z_mu) * torch.exp(z_sigma2_log / 2) + z_mu\n","        yita_c=torch.exp(torch.log(pi.unsqueeze(0))+self.gaussian_pdfs_log(z,mu_c,log_sigma2_c))+det\n","\n","        yita_c=yita_c/(yita_c.sum(1).view(-1,1))#batch_size*Clusters\n","\n","        Loss+=0.5*torch.mean(torch.sum(yita_c*torch.sum(log_sigma2_c.unsqueeze(0)+\n","                                                torch.exp(z_sigma2_log.unsqueeze(1)-log_sigma2_c.unsqueeze(0))+\n","                                                (z_mu.unsqueeze(1)-mu_c.unsqueeze(0)).pow(2)/torch.exp(log_sigma2_c.unsqueeze(0)),2),1))\n","\n","        Loss-=torch.mean(torch.sum(yita_c*torch.log(pi.unsqueeze(0)/(yita_c)),1))+0.5*torch.mean(torch.sum(1+z_sigma2_log,1))\n","\n","        return Loss\n","\n","    def gaussian_pdfs_log(self,x,mus,log_sigma2s):\n","        G=[]\n","        for c in range(self.args.nClusters):\n","            G.append(self.gaussian_pdf_log(x,mus[c:c+1,:],log_sigma2s[c:c+1,:]).view(-1,1))\n","        return torch.cat(G,1)\n","\n","\n","    @staticmethod\n","    def gaussian_pdf_log(x,mu,log_sigma2):\n","        return -0.5*(torch.sum(np.log(np.pi*2)+log_sigma2+(x-mu).pow(2)/torch.exp(log_sigma2),1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYn5MKz567nM"},"outputs":[],"source":["description='VaDE'\n","datadir='./mnist'\n","batch_size = 800\n","nClusters=10\n","hid_dim=10\n","cuda=True\n","\n","\n","class Args:\n","\n","    def __init__(self, description, batch_size, datadir, nClusters, hid_dim,\\\n","                 cuda):\n","        self.description = description\n","        self.batch_size = batch_size\n","        self.datadir = datadir\n","        self.nClusters = nClusters\n","        self.hid_dim = hid_dim\n","        self.cuda = cuda  \n","\n","args = Args(description, batch_size, datadir, nClusters, hid_dim, cuda)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyIGD1-d7euF"},"outputs":[],"source":["!pip install tensorboardX"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GItcCE8lbK2E"},"outputs":[],"source":["from tqdm import tqdm\n","import numpy as np\n","from torch.optim import Adam\n","from sklearn.metrics import accuracy_score\n","from torch.optim.lr_scheduler import StepLR\n","from tensorboardX import SummaryWriter\n","from sklearn.manifold import TSNE\n","import torch.nn as nn\n","\n","\n","def cluster_acc(Y_pred, Y):\n","    # from sklearn.utils.linear_assignment_ import linear_assignment\n","    # from scipy.optimize import linear_sum_assignment as linear_assignment\n","    assert Y_pred.size == Y.size\n","    D = max(Y_pred.max(), Y.max())+1\n","    w = np.zeros((D,D), dtype=np.int64)\n","    for i in range(Y_pred.size):\n","        w[Y_pred[i], Y[i]] += 1\n","    ind = linear_assignment(w.max() - w)\n","    return sum([w[i,j] for i,j in ind])*1.0/Y_pred.size, w\n","\n","\n","\n","DL, _ = get_mnist(datadir,batch_size)\n","\n","vade=VaDE(args)\n","if cuda:\n","    vade=vade.cuda()\n","    #Pour aller plus vite encore : (split de l'archi)\n","    # vade=nn.DataParallel(vade,device_ids=range(1))\n","\n","vade.pre_train(DL,pre_epoch=50)"]},{"cell_type":"code","source":["opti=Adam(vade.parameters(),lr=2e-3)\n","lr_s=StepLR(opti,step_size=10,gamma=0.95)\n","\n","writer=SummaryWriter('./logs')\n","epoch_bar=tqdm(range(300))\n","\n","\n","for epoch in epoch_bar:\n","\n","    lr_s.step()\n","    L=0\n","    for x,_ in DL:\n","        if cuda:\n","            x=x.cuda()\n","\n","        loss=vade.ELBO_Loss(x)\n","\n","        opti.zero_grad()\n","        loss.backward()\n","        opti.step()\n","\n","        L+=loss.detach().cpu().numpy()\n","\n","\n","    pre=[]\n","    tru=[]\n","\n","    with torch.no_grad():\n","        for x, y in DL:\n","            if cuda:\n","                x = x.cuda()\n","\n","            tru.append(y.numpy())\n","            pre.append(vade.predict(x))\n","\n","\n","    tru=np.concatenate(tru,0)\n","    pre=np.concatenate(pre,0)\n","\n","\n","    writer.add_scalar('loss',L/len(DL),epoch)\n","    writer.add_scalar('acc',cluster_acc(pre,tru)[0]*100,epoch)\n","    writer.add_scalar('lr',lr_s.get_lr()[0],epoch)\n","\n","    epoch_bar.write('Loss={:.4f},ACC={:.4f}%,LR={:.4f}'.format(L/len(DL),cluster_acc(pre,tru)[0]*100,lr_s.get_lr()[0]))"],"metadata":{"id":"OvP57PjBe9_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plotTSNE_vade(model, dataset, size=100, perplexity=30, n_iter=1000):\n","  model.eval() \n","  z = np.array([])\n","  first = True\n","  dataLoader = DataLoader(dataset, batch_size=128, shuffle=False,\n","                          num_workers=2)    \n","  it=iter(dataLoader)\n","\n","  if size is None:\n","      size=len(dataLoader)\n","\n","  # Calcul des vecteurs latents z\n","  nbreImgCount=0\n","  while(1):\n","          try :\n","              tmp=next(it)\n","          except:\n","              break    \n","          \n","          labels_batch = tmp[1]\n","          imgs = tmp[0]\n","          \n","          imgs = imgs.cuda()\n","          z_batch, _ = model.encoder(imgs)  # plong. dans l'espace latent\n","          # z_batch = torch.flatten(imgs, start_dim = 1) # si l'on veut tsne brute\n","          z_batch = z_batch.cpu().detach().numpy()\n","          \n","          if len(z) == 0:\n","              z = z_batch\n","              labels = labels_batch\n","\n","          else:\n","              z = np.concatenate((z,z_batch),axis=0)\n","              labels = np.concatenate((labels,labels_batch))\n","              \n","              \n","          nbreImgCount += len(imgs)\n","          print(nbreImgCount)\n","          if nbreImgCount >=size:\n","              break\n","\n","  print('Dim vecteurs espace latent : {}',z.shape[1])\n","\n","  # Calcul de la TSNE en 2D\n","\n","  X2 = TSNE(n_components=2,\n","            verbose=2,\n","            init='pca',\n","            n_iter=n_iter,\n","            perplexity=perplexity).fit_transform(z)\n","\n","  b=((labels-labels.min())/(labels.max()-labels.min())*255.).astype(int)\n","  c1 = cm.jet(b)\n","\n","  fig=plt.figure('TSNE 2D ')\n","  #ax2 = fig.add_subplot(111)\n","  #ax2.scatter(X2[:, 0], X2[:, 1],s=5,c=c1,marker='1')\n","  for i,label in enumerate(labels):\n","      plt.text(X2[i, 0], X2[i, 1],str(label),color=c1[i],fontsize=12)\n","      \n","  plt.xlabel('X')\n","  plt.ylabel('Y')\n","  plt.axis([-50,50,-50,50])     "],"metadata":{"id":"fPLt7TAr_XBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = vade\n","dataset = test_set  \n","size = 1000\n","n_iter = 1000\n","perplexity = 20\n","size= 1000\n","\n","plt.rcParams['figure.dpi'] = 200\n","plotTSNE(model, dataset, size=1000, perplexity=perplexity, n_iter=n_iter)"],"metadata":{"id":"GeSiR4TkugMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vade.encoder"],"metadata":{"id":"stYErK0SBBPL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Conclusion** \\\n","Avec cette dernière approche, on parvient à un partionnement presque parfait des données MNIST, sans aucune annonation manuelle. Ce type de méthode offre donc de nombreuses perspectives en matière de partionnement, de classification d'image, mais plus généralement de toute tâche où ré-entraîner un encodeur déjà appris peut laisser espérer une amélioration.\\\n","Evidemment, les chiffres de MNIST ne présentent pas la même difficulté que des images ou des sons réels. Mais d'un autre côté, les méthodes présentées ici sont rudimentaires. On trouve par exemple, dans la littérature, un panel de [tâches \"gratuites\"](https://project.inria.fr/paiss/files/2018/07/zisserman-self-supervised.pdf) (ie, sans besoin d'annotation) plus sophistiquées que la simple reproduction de l'entrée à laquelle est entraîné l'auto-encodeur de base.\n","\n"],"metadata":{"id":"Es-BxqA5cI_Z"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1UYLaF5zZauglud-0dOnQv0aGDCT3r8ZD","timestamp":1669984611531},{"file_id":"12YrKxCuPsuJo2PuZiUA4bw5FhhXy_X37","timestamp":1669935793550},{"file_id":"1EdCq8OdFztPUCVOYYsTpVvWbrloBa1YK","timestamp":1669903486590},{"file_id":"1uuAC25WpowNFFlmwcwb-w6pXdPirvtKo","timestamp":1669347264899},{"file_id":"1jxAGXknXdmA31l0X_7u9hMTmIQsIhCqi","timestamp":1669279686108},{"file_id":"1pspw1Siokq2mYd_m4nlQzaScfy_tmAi4","timestamp":1642630965738}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}