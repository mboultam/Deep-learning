{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LKNSQ_QW1Ipb_9wnk650sWP7EvFmQC6m","timestamp":1642738957837}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7hrd-WSf6I5Y"},"source":["**Partie IV** \n","\n","Dans cette partie, on s'intéresse à deux autres aspects importants du deep learning : l'accélération de l'apprentissage avec les cartes GPU et la possibilité d'utiliser des réseaux préentraînés.\n","\n","Pour illustrer le premier aspect, nous utiliserons les cartes gpu mises à disposition sous google colab. \n","Pour ce faire, avant de commencer la lecture du notebook, aller à **Modifier**/**Modifier les param du notebook** et sélectionner un gpu. \n","\n","Pour le second aspect, nous travaillerons sur un problème de classification binaire à partir d'un jeu de données de taille réduite (hymenoptera). Nous voyons l'intérêt d'utiliser un réseau qui a déjà été entraîné sur un jeu plus grand et sur une tâche de classification plus générale. "]},{"cell_type":"code","metadata":{"id":"w8-J_sK83SAA"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import time\n","\n","import torch\n","import torchvision\n","import torch.nn as nn   \n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, models, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgLvJixS8bsE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610201636097,"user_tz":-60,"elapsed":43428,"user":{"displayName":"pierre lepetit","photoUrl":"","userId":"18402625389605317532"}},"outputId":"a53d9aac-1b5a-4b89-990e-6928923faf3e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uO9dWAHQ1qzx","executionInfo":{"status":"ok","timestamp":1610201653639,"user_tz":-60,"elapsed":845,"user":{"displayName":"pierre lepetit","photoUrl":"","userId":"18402625389605317532"}},"outputId":"02ea1e25-617c-4db5-fa65-c823c52b57cb"},"source":["#vérification de la mise à disponibilité de la carte gpu:\n","print(torch.cuda.get_device_name(0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wndXhSn-6v0k"},"source":["**A.** Visualisation du jeu hymenoptera:"]},{"cell_type":"code","metadata":{"id":"g30QPYvJ6usN"},"source":["data_dir = '/content/drive/MyDrive/TP_ENM/data/hymenoptera_data'\n","\n","print(os.listdir(data_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tp8Wb2n3oO19"},"source":["Le jeu de données se présente sous une forme standard, on va pouvoir le manipuler avec un objet dataset prêt à l'emploi de la classe *datasets.ImageFolder*."]},{"cell_type":"code","metadata":{"id":"zB_qzRQvoDR-"},"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        #transforms.RandomVerticalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                             shuffle=True, num_workers=0)\n","              for x in ['train', 'val']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","\n","print('taille du jeu de données:' )\n","print(dataset_sizes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9WqaCTQPpM3v"},"source":["Comme le jeu de donnée mis à disposition est de très petite taille, il faut l'exploiter au maximum. On va donc produire de nouvelles images par des transformations supplémentaires qui conservent la nature de l'objet (augmentation de données). Dans le code, *transforms.RandomResizedCrop()* et *transforms.RandomHorizontalFlip()* et  *transforms.RandomVerticalFlip()* appliquent avec une probabilité de 1/2 une symétrie d'axe horizontal ou vertical. \\\\\n","Remarquez que ces transformations n'auraient pas pu être exploitées avec d'autres jeux de données comme MNIST: le symétrique d'une image de chiffre n'est généralement pas une image de chiffre. Il faut donc souvent adapter la transformation à la nature du jeu de données.\n","En dessous, on présente quelques images.\n","\n"]},{"cell_type":"code","metadata":{"id":"jRxgSsnkpAZd"},"source":["# Get a batch of training data\n","inputs, classes = next(iter(dataloaders['train']))\n","\n","def imshow(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","class_names = image_datasets['train'].classes\n","\n","out = torchvision.utils.make_grid(inputs)\n","imshow(out, title=[class_names[x] for x in classes])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQ2dPsjxAVUX"},"source":["**B.** Utilisation d'une carte graphique \\\\\n","\n","Dans un premier temps, nous allons vérifier que pour des architectures classiques comme le ResNet, l'utilisation d'une carte gpu améliore sensiblement le temps de calcul. \n","Commençons par charger la plus légère des architectures de type ResNet et écrivons la procédure d'apprentissage dans une fonction, une bonne fois pour toutes."]},{"cell_type":"markdown","metadata":{"id":"52_1BQUc-N9H"},"source":["**Exercice** \n","\n","- Charger un ResNet18 non pré-entraîné. Combien contient-il de poids au total ? Vérifier [ici](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html).\n","\n","- Combien de neurones la dernière couche du réseau comporte-t-elle ?\n","\n","- Compléter la fonction *train_model* prenant pour arguments un model, une fonction de coût, un optimizer et un nombre d'époques.\n"]},{"cell_type":"code","source":["model = models.resnet18( ... )   \n","print(model)"],"metadata":{"id":"DfRcKzhikRxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_weights = 0\n","\n","...\n","\n","print(nb_weights)"],"metadata":{"id":"bohrGmewkSdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nb de neurones dans la dernière couche : "],"metadata":{"id":"fM0kwUPQn6IH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mf97k7ze4x-E"},"source":["def train_model(model, loss_ft, optimizer, num_epochs=1):           \n","\n","    for epoch in range(num_epochs):\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  \n","            else:\n","                model.eval()   \n","\n","            # initialisation des compteurs\n","\n","            for inputs, labels in dataloaders[phase]:\n","\n","                # mise à zéro des incréments dans l'optimizer\n","\n","                # calcul des sorties (proba) et des prédictions (classe)\n","\n","                # fonction de coût\n","\n","                # gradients et backprop si entraînement \n","\n","                # compteurs\n","\n","            # Calcul du coût moyen et de la justesse sur l'époque\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lTJ6cf0flnw2"},"source":["Pour entraîner un resnet18, il faut d'abord modifier la dernière couche du classifieur de façon à ce qu'il y ait autant de neurones que de classes:"]},{"cell_type":"code","metadata":{"id":"n503vva5hbX4"},"source":["#Taille du vecteur d'entrée\n","num_ftrs = model.fc.in_features    \n","print(num_ftrs)\n","\n","#Nouvelle couche à deux neurones \n","model.fc = nn.Linear(num_ftrs, 2)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YFxO-wGjqpRv"},"source":["Pour le calcul de la log vraisemblance, il faudrait aussi ajouter une couche LogSoftmax. En effet, le ResNet comme les autres modèles standard s'arrête à la partie linéaire d'une couche complètement connectée.\n","Le plus simple est d'utiliser une fonction de coût qui incorpore la LogSoftmax. \\\\\n","Sous pytorch, c'est *nn.CrossEntropyLoss* qui combine *LogSoftmax* et *NLLLoss*."]},{"cell_type":"code","metadata":{"id":"_pbB5UV9qqgF"},"source":["loss_ft =  nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NaU7AXKAKJS_"},"source":["Lançons maintenant un entraînement sur une époque par batches de 64 images:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"fafNCRzhKHiT"},"source":["dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n","                                             shuffle=True, num_workers=2)\n","              for x in ['train', 'val']}\n","              \n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)    \n","\n","model = train_model(model, loss_ft, optimizer, num_epochs=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-3JiouQJKk2A"},"source":["Avec plus de 100 M de poids, l'entraînement d'un ResNet sur CPU est beaucoup plus long que les réseaux de la partie III. \\\\\n","Reprenons le même entraînement en utilisant la carte graphique. Pour cela, on doit préciser la carte sur laquelle passer les tenseurs: "]},{"cell_type":"code","metadata":{"id":"l1RzhRh4LQAA"},"source":["device = torch.device(\"cuda:0\") # if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-UxeaYxLbRQ"},"source":["Ensuite, on passe le model sur la carte graphique:"]},{"cell_type":"code","metadata":{"id":"yJNqVGBtLmkp"},"source":["model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ki5PIDPLw4Z"},"source":["Pour passer un tenseur sur la carte, la syntaxe est la même:"]},{"cell_type":"code","metadata":{"id":"0HUBH0MKMCN3"},"source":["x = torch.rand(2,1,4,4)\n","print(x)\n","x = x.to(device)\n","print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**remarques :**\n","\n","- Le nom de la carte apparaît maintenant lorsqu'on affiche le tenseur.\n","- On utilise aussi la méthode .cuda() lorsqu'il n'y a qu'une seule carte GPU. \n","- Pour rapatrier un tenseur (ou un modèle), on utilise la méthode .cpu() : "],"metadata":{"id":"OJcfryhsq9Ok"}},{"cell_type":"code","source":["print(x.cpu())"],"metadata":{"id":"JwznFsD6q-Ab"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KfXJyAFlMRQx"},"source":["**Exercice :** A partir de la fonction *train_model*, définir une fonction train_model_gpu où le calcul de l'output et des gradients se font sur la carte gpu. Comparer les performances en temps."]},{"cell_type":"code","source":["def train_model_gpu(model, loss_ft, optimizer, num_epochs=1) :\n","    ..."],"metadata":{"id":"Tp-0BUPurehE"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qV4MjaeMP-w"},"source":["model = train_model_gpu(model, loss_ft, optimizer, num_epochs=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPiZpob4xH7P"},"source":["**C.** Amélioration de la procédure d'entraînement\n","\n","Avant de comparer différentes approches de transfert, nous allons un peu améliorer la procédure d'entraînement.\n","D'abord, on peut ajouter une inertie (momentum) à la descente de gradient. Le  [calcul de l'incrément](https://pytorch.org/docs/master/optim.html#torch.optim.SGD) dépendra non seulement du gradient courant mais aussi des valeurs d'incrément passées, contenues dans $d_i$: \\\\\n","\n","\\begin{equation}\n","d_i^{t+1} = momentum \\times d_i^{t} +    \\dfrac{\\partial \\mathcal{L_{batch}^{t+1}}} {\\partial{\\omega_i}} \\\\\n","w_i^{t+1}  = w_i^{t} - lr \\times d_i^{t+1}\n","\\end{equation}\n"]},{"cell_type":"code","metadata":{"id":"7TmGnbP_zWoQ"},"source":["optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9zXmy-HFvWQR"},"source":["Ensuite nous ajoutons un *scheduler* qui permet de diminuer progressivement le taux d'apprentissage *lr*. Avec le *scheduler* suivant, toutes les cinq époques, *lr* est multiplié par gamma = 0.1. \\\\\n","Le *scheduler* doit avoir accès au *lr* contenu dans *optimizer*. Ce dernier est donc passé comme argument. Le *scheduler* n'agit sur le *lr* qu'à la fin d'une époque. Pour que cette action soit effective, il faudra ajouter en dehors de la boucle d'itération du loader: \\\\\n","\n","*scheduler.step()* \n"]},{"cell_type":"code","metadata":{"id":"nRLkBVCIuK-9"},"source":["scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DErP0Z3JvpEO"},"source":["**Exercice**: intégrer ces éléments dans la fonction d'entraînement. Faire en sorte, aussi, que la fonction d'entraînement renvoie les listes des scores (loss et justesse). Vérifier que le taux d'apprentissage décroit comme prévu.  \n","\n","*N.B.:* Sous pytorch, chaque poids est associé à un taux d'apprentissage.\n","        Ces taux d'apprentissage sont stockés dans *optimizer.param_groups*."]},{"cell_type":"code","source":[],"metadata":{"id":"cmYZjYM90Glu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Remarque:** On utilise généralement le paramétrage qui a obtenu les meilleurs scores sur le jeu de validation. Pour ça, on enregistre les poids en cours d'apprentissage, dès qu'un record en validation est atteint. Noter qu'en sélectionnant ainsi le modèle, on apprend le jeu de validation. \\\\\n","C'est la raison pour laquelle l'évaluation d'un modèle sélectionné sur le jeu de validation a toujours lieu sur un **jeu de test** indépendant des jeux de validation et d'entraînement.\n","\n","Pour information, voilà comment garder en mémoire les poids d'un modèle sous pytorch:"],"metadata":{"id":"_SU-_cE80Iru"}},{"cell_type":"code","source":["import copy\n","\n","# Dans la boucle :\n","if phase == \"val\" and epoch_acc > best_val_acc :\n","  best_model_wts = copy.deepcopy(model.state_dict())\n","  best_val_acc = epoch_acc\n","\n","# Après apprentissage :\n","model.load_state_dict(best_model_wts)"],"metadata":{"id":"TrR_AEcB0KSW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nA0YW6DKeIbD"},"source":["**D.** Effet d'un pré-entraînement sur les performances"]},{"cell_type":"markdown","source":["L'entraînement est plus rapide sur GPU, mais il ne conduit qu'à un score très médiocre, à peine meilleur que le hasard.\n","Pour améliorer les performances, une idée simple consiste utiliser un réseau entraîné sur une tâche similaire (ou plus générale) comme point de départ de l'apprentissage. On parle de ré-entraînement (ou **fine tuning**). \n","Ici, cela va particulièrement bien marcher avec des réseaux entraînés sur ImageNet, dont les les filtres de convolution sont déjà très riches. "],"metadata":{"id":"V36z-Ail4Ym-"}},{"cell_type":"markdown","metadata":{"id":"hMrZLn_5eVOg"},"source":["**Exercice**: \n","Modifier la fonction d'entraînement de façon à récupérer les justesses successives.\n","Reprendre l'apprentissage avec un ResNet18 non-préentraîné sur 25 époques. Comparer avec le même réseau préentraîné sur ImageNet (utiliser les courbes d'apprentissage). "]},{"cell_type":"code","source":["# Nouvelle fonction d'entraînement:\n","\n","def train_model_gpu(model, loss_ft, optimizer, num_epochs=1):\n","    ...\n","    return model, accs\n"],"metadata":{"id":"3Th-AFVI4-Oi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apprentissage \"from scratch\" (poids initialisés au hasard) :\n","# définition des modèle, optimizer, scheduler\n","# et lancement de l'entraînement\n","\n","resnet_scratch = torchvision.models.resnet18(pretrained=False)\n","\n","...\n","\n","resnet_scratch, accs_scratch = train_model_gpu(resnet_scratch, loss_function, optimizer, num_epochs=1)"],"metadata":{"id":"mhYdPwEfIjaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fine tuning :\n","# définition des modèle, optimizer, scheduler\n","# et lancement de l'entraînement\n","\n","\n","resnet_ft = torchvision.models.resnet18(pretrained=True)\n","\n","...\n","\n","resnet_ft, , accs_ft = train_model_gpu(resnet_ft, loss_function, optimizer, num_epochs=1)"],"metadata":{"id":"6Vhf2i8M4-f6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparaison des courbes d'apprentissage (justesse seulement)"],"metadata":{"id":"hr1ccuyUJGLL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["L'approche par fine tuning connaît de nombreuses variantes qui s'intègrent dans le cadre plus général de **l'apprentissage par transfert** (transfert learning).\n","Le fine tuning partiel qui est illustré dans l'exercice suivant est l'une de ces variantes."],"metadata":{"id":"MIf4G2jWC7Kg"}},{"cell_type":"markdown","metadata":{"id":"SDvNSDbVDlMA"},"source":["**Exercice :** Au lieu de réapprendre tous les poids, on peut se contenter de ceux du classifieur. On dit qu'on \"gèle\" les autres poids lors du ré-entraînement (**freezing**).\n","Mettre en place cette approche et comparer avec les précédentes."]},{"cell_type":"code","metadata":{"id":"EN4cwBcOLQsS"},"source":["# freezing :\n","# parcourir les paramètres du modèle \n","# et préciser ceux dont on ne veut\n","# pas calculer les gradient (méthode .requires_grad)\n","\n","\n","resnet_freezing = torchvision.models.resnet18(pretrained=True)\n","\n","...\n","\n","for param in ...\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IAjl5d6MDipO"},"source":["# Définition des modèle, optimizer, scheduler\n","# et lancement de l'entraînement"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparaison"],"metadata":{"id":"gdnBvyNeHhXm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oaXUV1Ea96gC"},"source":["Au final, pour ce petit jeu de données, le réapprentissage de la dernière couche permet de faire aussi bien qu'un entraînement global. \\\\\n","Voyons pour terminer quelques prédictions du modèle sur le jeu de validation:"]},{"cell_type":"code","metadata":{"id":"8yxcz-S8rJKD"},"source":["def visualize_model(model, num_images=6):\n","    was_training = model.training\n","    model.eval()\n","    images_so_far = 0\n","    fig = plt.figure()\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['val']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","\n","            for j in range(inputs.size()[0]):\n","                images_so_far += 1\n","                ax = plt.subplot(num_images//2, 2, images_so_far)\n","                ax.axis('off')\n","                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n","                imshow(inputs.cpu().data[j])\n","\n","                if images_so_far == num_images:\n","                    model.train(mode=was_training)\n","                    return\n","        model.train(mode=was_training)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzc5gNmAMGCK"},"source":["visualize_model(resnet_freezing)"],"execution_count":null,"outputs":[]}]}